{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23988ced",
   "metadata": {},
   "source": [
    "In this notebook my goal is to implement logistic regression from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e0c8a",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c29757",
   "metadata": {},
   "source": [
    "### Core idea\n",
    "Logistic regression is an algorithm that can be used to predict binary classification of the input - for example whether a statement is true or false. Instead of predicting a continous value, logistic regression predicts probablity of the input belonging to a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bf48c",
   "metadata": {},
   "source": [
    "### Mathematical view\n",
    "We start by calculating the linear combination of the input features:\n",
    "$$z = w^Tx + b$$\n",
    "where x is the feature vector, w is the weight vector and b is the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8713c",
   "metadata": {},
   "source": [
    "And now, to turn this into a probability between 0 and 1 we apply the sigmoid function:\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e3e08",
   "metadata": {},
   "source": [
    "Parameters w and b are learned by minimizing binary cross-entropy.\n",
    "\n",
    "$$Loss = -\\frac{1}{N} \\sum_{i=1}^{N}[y_ilog(\\hat{y}_i) + (1-y_i)log(1-\\hat{y}_i)]$$\n",
    "\n",
    "where $y_i$ is the true label, and $\\hat{y}$ is the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12863726",
   "metadata": {},
   "source": [
    "### Implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.01\n",
    "        self.num_iteration = 1000\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\" Sigmoid function that will translate prediction into probability between 0 and 1. \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predict_probability(self, X):\n",
    "        \"\"\" Calculating the probability \"\"\"\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(linear_output)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Function that train the model. Its goal is to find the best\n",
    "            values for weights and bias parameters by minimizing the error on training data. \"\"\"\n",
    "        \n",
    "        # Initializing the parameters\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for _ in range(self.num_iterations):\n",
    "            \n",
    "            # Predicting probability for each data point\n",
    "            y_pred = self.predict_probability(X)\n",
    "            \n",
    "            # Computing gradients - adjusting the weights and bias to reduce loss\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Updating parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate *db\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\" Function that predicts the final class labels\"\"\"\n",
    "        y_probs = self.predict_probability(X)\n",
    "        \n",
    "        # Formatting the output labels\n",
    "        binary_predictions = y_probs >= 0.5\n",
    "        return binary_predictions.astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
